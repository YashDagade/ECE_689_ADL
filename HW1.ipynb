{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y3XpY_hw1hb"
   },
   "source": [
    "# ECE 689, Spring 2025\n",
    "## Homework 1 \n",
    "\n",
    "## Full name: Yash Dagade\n",
    "## NetID: YD211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit the homework as pdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbqTTFeww1hf"
   },
   "source": [
    "## Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3lEjedRvw1hf"
   },
   "outputs": [],
   "source": [
    "# Import some useful packages, please edit as needed\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import copy\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bSLBTZOww1hh"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18165135/18165135 [00:31<00:00, 568506.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/train-images-idx3-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29497/29497 [00:00<00:00, 169982.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/train-labels-idx1-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3041136/3041136 [00:02<00:00, 1096059.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/t10k-images-idx3-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5120/5120 [00:00<00:00, 20808950.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw/t10k-labels-idx1-ubyte.gz to KMNIST/raw/train-images-idx3-ubyte/KMNIST/raw\n",
      "\n",
      "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2 to USPS/usps.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6579383/6579383 [00:05<00:00, 1197004.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import some datasets, please plot to make sure it works\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "\n",
    "ds_KMIST = torchvision.datasets.KMNIST('KMNIST/raw/train-images-idx3-ubyte', train=True, download=True,\n",
    "                                       transform=torchvision.transforms.Compose([\n",
    "                                           torchvision.transforms.Resize(16),\n",
    "                                           torchvision.transforms.ToTensor()]))\n",
    "ds_USPS  = torchvision.datasets.USPS('USPS', train=True, download=True,\n",
    "                                     transform=torchvision.transforms.Compose([\n",
    "                                         torchvision.transforms.Resize(16),\n",
    "                                         torchvision.transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some datasets, please plot to make sure it works\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# some github repos may already have this code,\n",
    "# do anything fancy e.g. 3 x 3 Gaussians or Gaussians in a circle like a donut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, I worked with:\n",
    "\n",
    "- (name, remark)\n",
    "- (name, remark)\n",
    "\n",
    "For this question, I referenced a few sites/ papers/ github repositories, especially:\n",
    "\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- ...\n",
    "\n",
    "I spent ... amount of time, I have some suggestions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCKUlYQ0w1hk",
    "tags": []
   },
   "source": [
    "## Question 1: Normalizing Flows\n",
    "\n",
    "- Select a coupling Normalizing Flow and an autoregressive Normalizing Flow (NF). \n",
    "- Apply the NF models to MNIST dataset.\n",
    "- You can resize the MNIST images to 7 × 7 pixels to reduce computational complexity.\n",
    "\n",
    "Some github repositories:\n",
    "- https://github.com/zhongyuchen/generative-models\n",
    "- https://github.com/kamenbliznashki/normalizing_flows\n",
    "- https://github.com/karpathy/pytorch-normalizing-flows\n",
    "- https://github.com/VincentStimper/normalizing-flows \n",
    "- remember to list these references below if you use them!\n",
    "- if you find some other references, do share too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, I worked with:\n",
    "\n",
    "- (name, remark)\n",
    "- (name, remark)\n",
    "\n",
    "For this question, I referenced a few sites/ papers/ github repositories, especially:\n",
    "\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- ...\n",
    "\n",
    "I spent ... amount of time, I have some suggestions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: WaveNet for Image Modeling\n",
    "\n",
    "- Pick a WaveNet-typed model (e.g., WaveNet, ParallelWaveNet).\n",
    "- Train the model for image modelling on MNIST.\n",
    "- You can resize the MNIST images to 7 × 7 pixels to reduce computational complexity.\n",
    "\n",
    "Some reference:\n",
    "- https://medium.com/@evinpinar/wavenet-implementation-and-experiments-2d2ee57105d5\n",
    "- https://github.com/kan-bayashi/ParallelWaveGAN?tab=readme-ov-file\n",
    "- https://github.com/Zeta36/tensorflow-image-wavenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, I worked with:\n",
    "\n",
    "- (name, remark)\n",
    "- (name, remark)\n",
    "\n",
    "For this question, I referenced a few sites/ papers/ github repositories, especially:\n",
    "\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- ...\n",
    "\n",
    "I spent ... amount of time, I have some suggestions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Energy-based Models\n",
    "\n",
    "- make a simple energy-based model with E(x,\\theta) = f_{\\theta}(x). Here, f_{\\theta}() is a simple 2-layer convolutional network (CNN). You should design this CNN yourself, which include (at least) 2 convolutional layers.\n",
    "- train and use Gibbs sampling and Langevin Dynamics method on USPS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, I worked with:\n",
    "\n",
    "- (name, remark)\n",
    "- (name, remark)\n",
    "\n",
    "For this question, I referenced a few sites/ papers/ github repositories, especially:\n",
    "\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- (remark, link)\n",
    "- ...\n",
    "\n",
    "I spent ... amount of time, I have some suggestions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in the above, start thinking about presentation topics and talk to Vahid. <br>\n",
    "If you are interested in something later on in the class, skim through the slides, also start thinking about presentation topics and talk to Vahid."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Template_ECE590_Spring2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
